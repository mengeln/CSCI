#Also includes outlier flags;
OE.final<-data.frame(O=OE.stats$OBS,E=OE.stats$E.prd,
OoverE=OE.stats$OBS/OE.stats$E.prd,
Onull=Obsnull,Enull=rep(Enull,length(Obsnull)),OoverE.null=Obsnull/Enull,
BC= OE.stats$BC.prd,BC.null=BC.null,
row.names=row.names(bugnew.pa));
return(OE.final)
}; #end of function;
oescore <- score(oe)
length(unique(stations$StationCode))
setMethod("rForest", "oe", function(object){
if(nrow(object@oesubsample)==0){object <- subsample(object)}
load("oe_stuff.rdata")
object@predictors <- merge(unique(object@oesubsample[, c("StationCode", "SampleID")]), object@predictors,
by="StationCode", all.x=FALSE)
row.names(object@predictors) <- paste0(object@predictors$StationCode, "%", object@predictors$SampleID)
print(length(unique(object@predictors$SampleID)))
iterate <- function(rep){
patable <- dcast(data=object@oesubsample[, c("StationCode", "SampleID", "STE", rep)],
StationCode + SampleID ~ STE,
value.var=rep,
fun.aggregate=function(x)sum(x)/length(x))
patable[is.na(patable)] <- 0
row.names(patable) <- paste(patable$StationCode, "%", patable$SampleID, sep="")
iresult <- model.predict.RanFor.4.2(bugcal.pa=oe_stuff[[2]],
grps.final=oe_stuff[[3]],
preds.final=oe_stuff[[4]],
ranfor.mod=oe_stuff[[1]],
prednew=object@predictors,
bugnew=patable,
Pc=0.5,
Cal.OOB=FALSE)
iresult$SampleID <- unique(patable$SampleID)
return(iresult)
}
object@fulliterations <- lapply(paste("Replicate", 1:20), function(i)iterate(i))
labels <- strsplit(row.names(object@fulliterations[[1]]), "%")
labels <- as.data.frame(matrix(unlist(labels), nrow=length(labels), byrow=T))
object@fulliterations <- lapply(object@fulliterations, function(l){
row.names(l)<-labels[, 2]
l
})
object@iterations <- do.call(cbind, lapply(object@fulliterations, function(l)l$OoverE))
object@oeresults <- data.frame(labels, apply(object@iterations, 1, mean))
names(object@oeresults) <- c("StationCode", "SampleID", "OoverE")
object
})
oescore <- score(oe)
setMethod("rForest", "oe", function(object){
if(nrow(object@oesubsample)==0){object <- subsample(object)}
load("oe_stuff.rdata")
object@predictors <- merge(unique(object@oesubsample[, c("StationCode", "SampleID")]), object@predictors,
by="StationCode", all.x=FALSE)
row.names(object@predictors) <- paste0(object@predictors$StationCode, "%", object@predictors$SampleID)
iterate <- function(rep){
patable <- dcast(data=object@oesubsample[, c("StationCode", "SampleID", "STE", rep)],
StationCode + SampleID ~ STE,
value.var=rep,
fun.aggregate=function(x)sum(x)/length(x))
patable[is.na(patable)] <- 0
row.names(patable) <- paste(patable$StationCode, "%", patable$SampleID, sep="")
iresult <- model.predict.RanFor.4.2(bugcal.pa=oe_stuff[[2]],
grps.final=oe_stuff[[3]],
preds.final=oe_stuff[[4]],
ranfor.mod=oe_stuff[[1]],
prednew=object@predictors,
bugnew=patable,
Pc=0.5,
Cal.OOB=FALSE)
iresult$SampleID <- unique(object@predictors$SampleID)
return(iresult)
}
object@fulliterations <- lapply(paste("Replicate", 1:20), function(i)iterate(i))
labels <- strsplit(row.names(object@fulliterations[[1]]), "%")
labels <- as.data.frame(matrix(unlist(labels), nrow=length(labels), byrow=T))
object@fulliterations <- lapply(object@fulliterations, function(l){
row.names(l)<-labels[, 2]
l
})
object@iterations <- do.call(cbind, lapply(object@fulliterations, function(l)l$OoverE))
object@oeresults <- data.frame(labels, apply(object@iterations, 1, mean))
names(object@oeresults) <- c("StationCode", "SampleID", "OoverE")
object
})
oescore <- score(oe)
summary(oescore)
oeoutput <- summary(oescore)
viewData(merge(oeoutput[, c("SampleID", "OoverE")], validation[, c("SampleID", "OoverE")], by="SampleID"))
viewData(merge(oeoutput[, c("SampleID", "OoverE")], validation[, c("SampleID", "OoverE")], by="SampleID"), all.y=TRUE)
viewData(merge(oeoutput[, c("SampleID", "OoverE")], validation[, c("SampleID", "OoverE")], by="SampleID", all.y=TRUE))
viewData(merge(oeoutput[, c("SampleID", "OoverE")], validation[, c("SampleID", "OoverE")], by="SampleID"))
viewData(merge(output[, c("SampleID", "MMI_Score", "Shannon_Diversity")], validation[, c("SampleID", "MMI", "Shannon_Diversity")], by="SampleID"))
viewData(merge(oeoutput[, c("SampleID", "OoverE")], validation[, c("SampleID", "OoverE")], by="SampleID"))
viewData(oeoutput)
scores <- score(nameMatch(mmi, 1))
output <- summary(scores)
source('~/.active-rstudio-document', echo=TRUE)
scores <- score(nameMatch(mmi, 1))
traceback()
scores <- score(nameMatch(mmi, 2))
traceback()
setMethod("subsample", "mmi", function(object){
if(is.null(object@bugdata$distinct)){object <- nameMatch(object)}
object@datalength <- length(object@bugdata)
object@bugdata$SampleID <- as.character(object@bugdata$SampleID)
rarifydown <- function(data){unlist(sapply(unique(data$SampleID), function(sample){
v <- data[data$SampleID==sample, "Result"]
if(sum(v)>=500){rrarefy(v, 500)} else
{v}
}))}
registerDoParallel()
rarificationresult <- foreach(i=1:20, .combine=cbind, .packages="vegan") %dopar% {
rarifydown(object@bugdata)
}
closeAllConnections()
object@subsample <- as.data.frame(cbind(object@bugdata, rarificationresult))
colnames(object@subsample)[(object@datalength + 1):(object@datalength + 20)]<- paste("Replicate", 1:20)
return(object)
})
scores <- score(nameMatch(mmi, 2))
output <- summary(scores)
names(output)[6] <- "Tolerance_Value"
viewData(merge(output[, c("SampleID", "MMI_Score", "Shannon_Diversity")], validation[, c("SampleID", "MMI", "Shannon_Diversity")], by="SampleID"))
scores <- score(nameMatch(mmi, 1))
output <- summary(scores)
viewData(merge(output[, c("SampleID", "MMI_Score", "Shannon_Diversity")], validation[, c("SampleID", "MMI", "Shannon_Diversity")], by="SampleID"))
viewData(output)
viewData(merge(output[, c("SampleID", "MMI_Score", "Shannon_Diversity")], validation[, c("SampleID", "MMI", "Shannon_Diversity")], by="SampleID"))
output <- summary(scores)
viewData(output)
validation_merge <- merge(output[, c("SampleID", "MMI_Score", names)], validation[, c("SampleID", "MMI", names)], by="SampleID")
validation_merge <- merge(output[, c("SampleID", "MMI Score", names)], validation[, c("SampleID", "MMI", names)], by="SampleID")
names(output)[6] <- "Tolerance_Value"
validation_merge <- merge(output[, c("SampleID", "MMI_Score", names)], validation[, c("SampleID", "MMI", names)], by="SampleID")
viewData(validation_merge)
scores <- score(nameMatch(mmi, 1))
source('~/.active-rstudio-document', echo=TRUE)
scores <- score(nameMatch(mmi, 1))
output <- summary(scores)
viewData(merge(output[, c("SampleID", "MMI_Score", "Shannon_Diversity")], validation[, c("SampleID", "MMI", "Shannon_Diversity")], by="SampleID"))
source('P:/PartTimers/MarkEngeln/bug_mmi/redo.r', echo=TRUE)
abs(validation_merge$MMI_Score - validation_merge$MMI)
oescore@oeresults
summary(oescore, "full")
summary(oescore, "detail")
summary(oescore, "detailed")
summary(new("metricMean", scores, oescore))
new("metricMean", scores, oescore)
source('~/.active-rstudio-document', echo=TRUE)
summary(new("metricMean", scores, oescore))
oescore@fulliterations[[1]]
oescore@fulliterations[[1]][, c("SampleID", "E")]
oescore@fulliterations[[1]][, c("SampleID", "0", "E")]
names(oescore@fulliterations[[1]])
oescore@fulliterations[[1]][, c("O", "E")]
oescore@fulliterations[[1]][, c("SampleID", "O", "E")]
oescore@fulliterations[[2]][, c("SampleID", "O", "E")]
merge(oescore@fulliterations[[2]][, c("SampleID","OoverE", "O", "E")], validation[, c("SampleID", "OoverE", "O", "E")], by="SampleID")
viewData(merge(oescore@fulliterations[[2]][, c("SampleID","OoverE", "O", "E")], validation[, c("SampleID", "OoverE", "O", "E")], by="SampleID"))
viewData(merge(output[, c("SampleID", "MMI_Score", "Shannon_Diversity")], validation[, c("SampleID", "MMI", "Shannon_Diversity")], by="SampleID"))
oescore@fulliterations[[1]]
viewData(oescore@fulliterations[[1]])
bugsnew <- subset(bugs, SampleID %in% intersect(bugs$StationCode, stations$StationCode))
intersect(bugs$StationCode, stations$StationCode)
bugsnew <- subset(bugs, SampleID %in% intersect(StationCode, stations$StationCode))
bugsnew <- bugs[bugs$SampleID %in% intersect(bugs$StationCode, stations$StationCode)])
bugsnew <- bugs[bugs$SampleID %in% intersect(bugs$StationCode, stations$StationCode)]
bugsnew <- bugs[bugs$SampleID %in% intersect(bugs$StationCode, stations$StationCode),]
intersect(bugs$StationCode, stations$StationCode)
bugs$SampleID %in% intersect(bugs$StationCode, stations$StationCode)
bugsnew <- bugs[bugs$StationCode %in% intersect(bugs$StationCode, stations$StationCode),]
fulltest <- new("metricMean", new("mmi", bugsnew, stations), new("oe", bugsnew, stations))
mmi_result <- new("mmi", bugsnew, stations)
oe_result <- new("oe", bugsnew, stations)
fulltest <- new("metricMean", mmi_result, oe_result)
summary(mmi_result)
mmi_result <- score(new("mmi", bugsnew, stations))
oe_result <- score(new("oe", bugsnew, stations))
fulltest <- new("metricMean", mmi_result, oe_result)
viewData(summary(fulltest))
fulltest <- new("metricMean", mmi_result, oe_result, "complete")
str(summary(fulltest, "complete"))
str(summary(fulltest, "detailed"))
str(summary(fulltest))
str(summary(fulltest, "standard"))
names(fulltest@metrics)
names(fulltest@modelprediction)
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class3_metricMean.r', echo=TRUE)
str(summary(fulltest))
str(summary(fulltest, "detailed"))
source('~/.active-rstudio-document', echo=TRUE)
str(summary(fulltest, "detailed"))
source('~/.active-rstudio-document', echo=TRUE)
str(summary(fulltest, "detailed"))
source('~/.active-rstudio-document', echo=TRUE)
str(summary(fulltest, "detailed"))
fulltest@oeresults
fulltest@iterations
apply(bugcal.pa,2,function(x){tapply(x,grps.final,function(y){sum(y)/length(y)})})
predict(oe_stuff[[1]],newdata=fulltest@predictors[,oe_stuff[[4]]],type='prob') %*% apply(bugcal.pa,2,function(x){tapply(x,grps.final,function(y){sum(y)/length(y)})})
source('~/.active-rstudio-document', echo=TRUE)
str(summary(fulltest, "detailed"))
viewData(summary(fulltest, "detailed"))
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class3_metricMean.r', echo=TRUE)
fulltest <- new("metricMean", mmi_result, oe_result)
viewData(summary(fulltest, "detailed"))
viewData(summary(fulltest, "detailed"))
viewData(summary(fulltest, "detailed"))
viewData(fulltest@metrics)
source('~/.active-rstudio-document', echo=TRUE)
mmi_result <- score(new("mmi", bugsnew, stations))
oe_result <- score(new("oe", bugsnew, stations))
fulltest <- new("metricMean", mmi_result, oe_result)
viewData(summary(fulltest, "detailed"))
viewData(merge(summary(fulltest), validation[, c("SampleID", "MMI", "OoverE", "CSCI")], by="SampleID"))
viewData(summary(fulltest, "detailed"))
str(summary(fullest, "complete"))
str(summary(fulltest, "complete"))
names(summary(fulltest, "complete"))
str(summary(fulltest, "complete"))
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class3_metricMean.r', echo=TRUE)
str(summary(fulltest, "complete"))
viewData(summary(fulltest, "detailed"))
reports <- lapply(c("core", "Supp1_mmi", "Suppl1_grps", "Suppl1_OE.E", "Suppl1_OE.O"), function(report)summary(fulltest, report))
report_names <- c("core", "Supp1_mmi", "Suppl1_grps", "Suppl1_OE.E", "Suppl1_OE.O")
lapply(1:5, function(i)write.csv(reports[[i]], file=paste0("C:/Documents and Settings/gisuser/Desktop/", report_names[i], ".csv")))
reports[[1]]
reports[1]
reports
reports <- lapply(report_names, function(report)summary(fulltest, report))
reports
library(hybridindex)
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class3_metricMean.r', echo=TRUE)
reports <- lapply(report_names, function(report)summary(fulltest, report))
library(plyr)
reports <- lapply(report_names, function(report)summary(fulltest, report))
library(reshape2)
reports <- lapply(report_names, function(report)summary(fulltest, report))
reports
lapply(1:5, function(i)write.csv(reports[[i]], file=paste0("C:/Documents and Settings/gisuser/Desktop/", report_names[i], ".csv")))
source('~/.active-rstudio-document', echo=TRUE)
reports <- lapply(report_names, function(report)summary(fulltest, report))
lapply(1:5, function(i)write.csv(reports[[i]], file=paste0("C:/Documents and Settings/gisuser/Desktop/", report_names[i], ".csv")))
paste0("pGroup", 1:11)
colnames
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class3_metricMean.r', echo=TRUE)
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class3_metricMean.r', echo=TRUE)
report_names <- c("core", "Supp1_mmi", "Suppl1_grps", "Suppl1_OE.E", "Suppl1_OE.O")
reports <- lapply(report_names, function(report)summary(fulltest, report))
lapply(1:5, function(i)write.csv(reports[[i]], file=paste0("C:/Documents and Settings/gisuser/Desktop/", report_names[i], ".csv")))
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class3_metricMean.r', echo=TRUE)
reports <- lapply(report_names, function(report)summary(fulltest, report))
lapply(1:5, function(i)write.csv(reports[[i]], file=paste0("C:/Documents and Settings/gisuser/Desktop/", report_names[i], ".csv")))
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class2_oe.r', echo=TRUE)
library(CSCI)
library(RSQLite)
con <- dbConnect("sqlite", "hybridindex/Data/bug_metadata_test.db.db")
con <- dbConnect("SQLITE", "hybridindex/Data/bug_metadata_test.db.db")
con <- dbConnect("SQLiteConnection", "hybridindex/Data/bug_metadata_test.db.db")
?dbConnect
?RSQLite
con <- dbConnect("SQLite", "hybridindex/Data/bug_metadata_test.db.db")
dbListTables(con)
con <- dbConnect("SQLite", "hybridindex/Data/bug_metadata_test.db")
dbListTables(con)
ibi <- dbGetQuery(con, "SELECT * FROM ibi")
View(ibi)
write.csv(ibi, file="C:/Documents and Settings/gisuser/Desktop/csci_metadata.csv")
unique(ibi$CustomSTE)
sort(unique(ibi$CustomSTE))
otu <- dbGetQuery(con, "SELECT * FROM otu_crosswalk")
View(otu)
ibi_otu <- merge(ibi, otu)
View(ibi_otu)
ibi_otu <- merge(ibi, otu, by="FinalID")
View(ibi_otu)
View(otu)
View(ibi_otu)
ibi <- dbGetQuery(con, "SELECT * FROM ibitable2")
library(RSQLite)
con <- dbConnect("SQLite", "hybridindex/Data/bug_metadata_test.db")
ibi <- dbGetQuery(con, "SELECT * FROM ibitable2")
con <- dbConnect("SQLite", "hybridindex/Data/bug_metadata.db")
ibi <- dbGetQuery(con, "SELECT * FROM ibitable2")
View(ibi)
write.csv(ibi, file="C:/Documents and Settings/gisuser/Desktop/csci_metadata.csv")
ibi <- subset(dbGetQuery(con, "SELECT * FROM ibitable2"), !(SAFIT1__OTU_a_original %in% "Ambiguous"))
nrow(ibi)
write.csv(ibi, file="C:/Documents and Settings/gisuser/Desktop/csci_metadata.csv")
write.csv(ibi, file="C:/Documents and Settings/gisuser/Desktop/csci_metadata.csv")
ibi <- subset(dbGetQuery(con, "SELECT * FROM ibitable2"), !(SAFIT1__OTU_a_original %in% c("Ambiguous", "Unambiguous_NotAtRefCal", "Exclude")"))
nrow(ibi)
write.csv(ibi, file="C:/Documents and Settings/gisuser/Desktop/csci_metadata.csv")
ibi <- subset(dbGetQuery(con, "SELECT * FROM ibitable2"), !(SAFIT1__OTU_a %in% c("Ambiguous", "Unambiguous_NotAtRefCal", "Exclude")"))
ibi <- subset(dbGetQuery(con, "SELECT * FROM ibitable2"), !(SAFIT1__OTU_a %in% c("Ambiguous", "Unambiguous_NotAtRefCal", "Exclude")))
nrow(ibi)
write.csv(ibi, file="C:/Documents and Settings/gisuser/Desktop/csci_metadata.csv")
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class2_mmi.r', echo=TRUE)
library(RSQLite)
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class2_mmi.r', echo=TRUE)
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class1_bugs.r', echo=TRUE)
rm(list=ls())
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/0_generics.r', echo=TRUE)
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/0_helpers.r', echo=TRUE)
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class1_bugs.r', echo=TRUE)
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class2_mmi.r', echo=TRUE)
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class2_oe.r', echo=TRUE)
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class3_metricMean.r', echo=TRUE)
stations <- read.csv("C:/Documents and Settings/gisuser/Desktop/stations.demo.csv")
bugs <- read.csv("C:/Documents and Settings/gisuser/Desktop/bugs.demo.csv")
bugs
mmi <- new("mmi", stations, bugs)
mmi_s <- score(mmi)
library(RSQLite)
library(BMIMetrics)
mmi_s <- score(mmi)
View(bugs)
mmi <- new("mmi", stations, bugs)
mmi_s <- score(mmi)
mmi_s <- nameMatch(mmi)
traceback()
mmi <- new("mmi", stations, bugs)
mmi_s <- nameMatch(mmi)
View(bugs)
names(bugs)
mmi@bugdata
names(mmi@bugdata)
mmi <- new("mmi", bugs, stations)
mmi_s <- score(mmi)
library(foreach)
mmi_s <- score(mmi)
library(doParallel)
mmi_s <- score(mmi)
library(data.table)
mmi_s <- score(mmi)
traceback()
mmi_s <- rForest(mmi)
mmi_s <- metrics(mmi)
rForest(mmi_s)
traceback()
head(mmi_s@modelprediction)
source('~/.active-rstudio-document', echo=TRUE)
mmi_s <- metrics(mmi)
mmi_s@metrics
rForest(mmi_s)
source('~/.active-rstudio-document', echo=TRUE)
rForest(mmi_s)
source('~/.active-rstudio-document', echo=TRUE)
rForest(mmi_s)
source('~/.active-rstudio-document', echo=TRUE)
rForest(mmi_s)
mmi_s <- scoremmi)
mmi_s <- score(mmi)
traceback()
mmi_s <- rForest(mmi)
mmi_s@modelprediction
View(mmi_s@modelprediction)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
mmi_s <- score(mmi)
source('~/.active-rstudio-document', echo=TRUE)
mmi_s <- score(mmi)
source('~/.active-rstudio-document', echo=TRUE)
mmi_s <- score(mmi)
source('~/.active-rstudio-document', echo=TRUE)
mmi_s <- score(mmi)
source('~/.active-rstudio-document', echo=TRUE)
mmi_s <- score(mmi)
source('~/.active-rstudio-document', echo=TRUE)
mmi_s <- score(mmi)
source('~/.active-rstudio-document', echo=TRUE)
mmi_s <- score(mmi)
source('~/.active-rstudio-document', echo=TRUE)
mmi_s <- score(mmi)
traceback()
mmi_s <- rForest(mmi)
mmi_@modelpredictions
mmi_s@modelpredictions
mmi_s@modelprediction
source('~/.active-rstudio-document', echo=TRUE)
score(mmi_s)
mmi_s@metrics
source('~/.active-rstudio-document', echo=TRUE)
mmi_s <- rForest(mmi)
score(mmi_s)
mmi_s@metrics
source('~/.active-rstudio-document', echo=TRUE)
mmi_s <- rForest(mmi)
source('~/.active-rstudio-document', echo=TRUE)
mmi_s <- rForest(mmi)
score(mmi_s)
mmi_s@metrics
source('~/.active-rstudio-document', echo=TRUE)
mmi_s <- rForest(mmi)
source('~/.active-rstudio-document', echo=TRUE)
mmi_s <- rForest(mmi)
source('~/.active-rstudio-document', echo=TRUE)
mmi_s <- rForest(mmi)
score(mmi_s)
load("P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/Data/maxmin.rdata")
score(mmi_s)
source('~/.active-rstudio-document', echo=TRUE)
score(mmi_s)
source('~/.active-rstudio-document', echo=TRUE)
score(mmi_s)
source('~/.active-rstudio-document', echo=TRUE)
score(mmi_s)
source('~/.active-rstudio-document', echo=TRUE)
score(mmi_s)
source('~/.active-rstudio-document', echo=TRUE)
score(mmi_s)
source('~/.active-rstudio-document', echo=TRUE)
score(mmi_s)
source('~/.active-rstudio-document', echo=TRUE)
mmi_s <- score(mmi)
summary(mmi_s)
oe <- new("oe", bugs, stations)
oe_s <- score(oe)
library(reshape2)
oe_s <- score(oe)
rm(list=ls())
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/0_generics.r', echo=TRUE)
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/0_helpers.r', echo=TRUE)
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class1_bugs.r', echo=TRUE)
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class2_oe.r', echo=TRUE)
library(RSQLite)
library(BMIMetrics)
library(foreach)
library(doParallel)
library(data.table)
library(reshape2)
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class1_bugs.r', echo=TRUE)
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class2_mmi.r', echo=TRUE)
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class3_metricMean.r', echo=TRUE)
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class3_metricMean.r', echo=TRUE)
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class3_metricMean.r', echo=TRUE)
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class2_oe.r', echo=TRUE)
stations <- read.csv("C:/Documents and Settings/gisuser/Desktop/stations.demo.csv")
bugs <- read.csv("C:/Documents and Settings/gisuser/Desktop/bugs.demo.csv")
mmi <- new("mmi", bugs, stations)
mmi_s <- score(mmi)
load("hybridindex/Data/maxmin.rdata")
mmi_s <- score(mmi)
View(summary(mmi_s))
oe <- new("oe", bugs, stations)
oe_s <- score(oe)
oe_s <- rForest(oe)
oe_s <- subsample(oe)
oe_s@oesubsample
head(oe_s@oesubsample)
source('~/.active-rstudio-document', echo=TRUE)
score(oe_s)
source('~/.active-rstudio-document', echo=TRUE)
score(oe_s)
source('~/.active-rstudio-document', echo=TRUE)
score(oe_s)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
e
score(oe_s)
source('~/.active-rstudio-document', echo=TRUE)
score(oe_s)
source('~/.active-rstudio-document', echo=TRUE)
score(oe_s)
source('~/.active-rstudio-document', echo=TRUE)
score(oe_s)
source('~/.active-rstudio-document', echo=TRUE)
score(oe_s)
source('~/.active-rstudio-document', echo=TRUE)
score(oe_s)
source('~/.active-rstudio-document', echo=TRUE)
score(oe_s)
oe_s <- score(oe)
res <- new("metricMean", mmi_s, oe_s)
summary(res)
summary(res, report="Supp1_mmi")
summary(res, report="Supp1_mmi")
summary(res, report="Supp1_OE.E")
summary(res, report="Supp1_OE.O")
summary(res, report="Supp1_OE.E")
traceback()
load("P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/Data/oe_stuff.rdata")
summary(res, report="Supp1_OE.E")
summary(res, report="Supp1_OE.O")
View(summary(res, report="Supp1_OE.O"))
oe_stuff[[1]]
summary(res, report="Suppl1_grps")
View(summary(res, report="Supp1_OE.O"))
bugcal.pa
source('~/.active-rstudio-document', echo=TRUE)
summary(res, report="Supp1_OE.E")
summary(res, report="Suppl1_OE.E")
oe_stuff
str(oe_stuff)
source('~/.active-rstudio-document', echo=TRUE)
summary(res, report="Suppl1_OE.E")
source('~/.active-rstudio-document', echo=TRUE)
summary(res, report="Suppl1_OE.E")
summary(res, report="Suppl1_OE.O")
lapply(c("core", "Supp1_mmi", "Suppl1_grps", "Suppl1_OE.E", "Suppl1_OE.O"),
function(rep)write.csv(summary(res, report=rep), file=paste0("C:/Documents and Settings/gisuser/Desktop/", rep, ".csv")))
source('~/.active-rstudio-document', echo=TRUE)
?source
sourceDir <- function(path, trace = TRUE, ...) {
for (nm in list.files(path, pattern = "\\.[RrSsQq]$")) {
if(trace) cat(nm,":")
source(file.path(path, nm), ...)
if(trace) cat("\n")
}
}
sourceDir("hybridindex/R/")
source('~/.active-rstudio-document', echo=TRUE)
