scores <- score(nameMatch(mmi, 2))
setMethod("subsample", "mmi", function(object){
if(is.null(object@bugdata$distinct)){object <- nameMatch(object)}
object@datalength <- length(object@bugdata)
object@bugdata$SampleID <- as.character(object@bugdata$SampleID)
#   rarifydown <- function(data){unlist(sapply(unique(data$SampleID), function(sample){
#     v <- data[data$SampleID==sample, "Result"]
#     if(sum(v)>=500){rrarefy(v, 500)} else
#     {v}
#   }))}
rarifydown <- function(data){sapply(split(data, data$SampleID), function(v){
#v <- data[data$SampleID==sample, "Result"]
if(sum(v$Result)>=500){rrarefy(v$Result, 500)} else
{v$Result}
})}
registerDoParallel()
rarificationresult <- foreach(i=1:20, .combine=cbind, .packages="vegan") %dopar% {
rarifydown(droplevels(object@bugdata))
}
closeAllConnections()
object@subsample <- as.data.frame(cbind(object@bugdata, rarificationresult))
colnames(object@subsample)[(object@datalength + 1):(object@datalength + 20)]<- paste("Replicate", 1:20)
return(object)
})
scores <- score(nameMatch(mmi, 2))
split(mmi@bugdata, mmi@bugdata$SampleID)
sapply(split(mmi@bugdata, mmi@bugdata$SampleID), nrow)
traceback()
setMethod("subsample", "mmi", function(object){
if(is.null(object@bugdata$distinct)){object <- nameMatch(object)}
object@datalength <- length(object@bugdata)
object@bugdata$SampleID <- as.character(object@bugdata$SampleID)
#   rarifydown <- function(data){unlist(sapply(unique(data$SampleID), function(sample){
#     v <- data[data$SampleID==sample, "Result"]
#     if(sum(v)>=500){rrarefy(v, 500)} else
#     {v}
#   }))}
rarifydown <- function(data){sapply(split(data, data$SampleID), function(v){
#v <- data[data$SampleID==sample, "Result"]
if(sum(v$Result)>=500){rrarefy(v$Result, 500)} else
{v$Result}
})}
registerDoParallel()
rarificationresult <- foreach(i=1:20, .combine=cbind, .packages="vegan") %dopar% {
rarifydown(object@bugdata)
}
print(str(rarificationresult))
closeAllConnections()
object@subsample <- as.data.frame(cbind(object@bugdata, rarificationresult))
colnames(object@subsample)[(object@datalength + 1):(object@datalength + 20)]<- paste("Replicate", 1:20)
return(object)
})
scores <- score(nameMatch(mmi, 2))
1+1
test@bugdata$BAResult == test@subsample$BAResult
test@bugdata$BAResult == bugs$BAResult
test@bugdata$BAResult == mmi@bugdata
test@bugdata$BAResult == mmi@bugdata$BAResult
paste0(test@bugdata$BAResult, test@bugdata$FinalID) == paste0(mmi@bugdata$BAResult, mmi@bugdata$FinalID)
unique(paste0(test@bugdata$BAResult, test@bugdata$FinalID, test@bugdata$SampleID)) %in%
unique(paste0(mmi@bugdata$BAResult, mmi@bugdata$FinalID, mmi@bugdata$SampleID))
unique(paste0(test@subsample$BAResult, test@subsample$FinalID, test@subsample$SampleID)) %in%
unique(paste0(mmi@bugdata$BAResult, mmi@bugdata$FinalID, mmi@bugdata$SampleID))
viewData(validation_merge)
subset(test@subsample, SampleID == "801PS0019_801PS0019_5/20/2008 0:00:00_BMI_RWB_1")
subset(test@subsample, SampleID == "801PS0019_801PS0019_5/20/2008 0:00:00_BMI_RWB_1")$BAResult
?diversity
diversity(subset(test@subsample, SampleID == "801PS0019_801PS0019_5/20/2008 0:00:00_BMI_RWB_1")$BAResult)
diversity(subset(test@subsample, SampleID == "801PS0019_801PS0019_5/20/2008 0:00:00_BMI_RWB_1")$"Replicate 1")
diversity(subset(test@subsample, SampleID == "801PS0019_801PS0019_5/20/2008 0:00:00_BMI_RWB_1")$"Replicate 2")
diversity(subset(test@subsample, SampleID == "801PS0019_801PS0019_5/20/2008 0:00:00_BMI_RWB_1")$"Replicate 3")
viewData(merge(scores@metrics[, c("SampleID", "MMI_Score", "Shannon_Diversity")], validation[, c("SampleID", "MMI", "Shannon_Diversity")], by="SampleID"))
@metrics[, c("SampleID", "MMI_Score", "Shannon_Diversity")]
scores@metrics[, c("SampleID", "MMI_Score", "Shannon_Diversity")]
scores@metrics
output[, c("SampleID", "MMI_Score", "Shannon_Diversity")]
viewData(merge(output[, c("SampleID", "MMI_Score", "Shannon_Diversity")], validation[, c("SampleID", "MMI", "Shannon_Diversity")], by="SampleID"))
diversity(subset(bugs, SampleID == "801S00766_SMC00766_7/11/2011 0:00:00_BMI_RWB_MCM_2")$BAResult)
diversity(subset(bugs, SampleID == "801S00899_SMC00899_7/12/2011 0:00:00_BMI_RWB_MCM_1")$BAResult)
diversity(subset(test@subsample, SampleID == "801S00899_SMC00899_7/12/2011 0:00:00_BMI_RWB_MCM_1")$BAResult)
diversity(subset(test@subsample, SampleID == "801S00899_SMC00899_7/12/2011 0:00:00_BMI_RWB_MCM_1")$"Replicate 1")
diversity(subset(test@subsample, SampleID == "801S00899_SMC00899_7/12/2011 0:00:00_BMI_RWB_MCM_1")$"Replicate 2")
diversity(subset(test@subsample, SampleID == "801S00899_SMC00899_7/12/2011 0:00:00_BMI_RWB_MCM_1")$"Replicate 3")
diversity(subset(test@subsample, SampleID == "801PS0019_801PS0019_5/20/2008 0:00:00_BMI_RWB_1")$"Replicate 3")
diversity(subset(test@subsample, SampleID == "801PS0019_801PS0019_5/20/2008 0:00:00_BMI_RWB_1")$BAResult)
diversity(subset(bugs, SampleID == "801PS0019_801PS0019_5/20/2008 0:00:00_BMI_RWB_1")$BAResult)
names
viewData(merge(output[, c("SampleID", "MMI_Score", "Intolerant_PercentTaxa")], validation[, c("SampleID", "MMI", "Intolerant_PercentTaxa")], by="SampleID"))
viewData(validation_merge)
which(abs(validation_merge$MMI_Score - validation_merge$MMI_Score) > 0.2)
abs(validation_merge$MMI_Score - validation_merge$MMI_Score)
which(abs(validation_merge$MMI_Score - validation_merge$MMI) > 0.2)
abs(validation_merge$MMI_Score - validation_merge$MMI)
which(abs(validation_merge$MMI_Score - validation_merge$MMI) > 0.1)
viewData(merge(output[, c("SampleID", "MMI_Score", "Shannon_Diversity")], validation[, c("SampleID", "MMI", "Shannon_Diversity")], by="SampleID"))
load("~/Desktop/OE.RFModel.Rdata")
grps.final
rf.mod
bugspa
viewData(bugcal.pa)
oe_stuff <- list(rf.mod, bugcal.pa, grps.final, preds.final)
oe_stuff
rf.mod
str(rf.mod)
viewData(bugcal.pa)
save(oe_stuff, file="oe_stuff.rdata")
oe_stuff[[2]]
setMethod("rForest", "oe", function(object){
if(nrow(object@oesubsample)==0){object <- subsample(object)}
load("oe_stuff.rdata")
object@predictors <- merge(unique(object@oesubsample[, c("StationCode", "SampleID")]), object@predictors,
by="StationCode")
row.names(object@predictors) <- paste0(object@predictors$StationCode, "%", object@predictors$SampleID)
iterate <- function(rep){
patable <- dcast(data=object@oesubsample[, c("StationCode", "SampleID", "STE", rep)],
StationCode + SampleID ~ STE,
value.var=rep,
fun.aggregate=function(x)sum(x)/length(x))
patable[is.na(patable)] <- 0
row.names(patable) <- paste(patable$StationCode, "%", patable$SampleID, sep="")
iresult <- model.predict.RanFor.4.2(bugcal.pa=oe_stuff[[2]],
grps.final=oe_stuff[[3]],
preds.final=oe_stuff[[4]]),
ranfor.mod=oe_stuff[[1]],
prednew=object@predictors,
bugnew=patable,
Pc=0.5,
Cal.OOB=FALSE)
iresult$SampleID <- unique(patable$SampleID)
return(iresult)
}
object@fulliterations <- lapply(paste("Replicate", 1:20), function(i)iterate(i))
labels <- strsplit(row.names(object@fulliterations[[1]]), "%")
labels <- as.data.frame(matrix(unlist(labels), nrow=length(labels), byrow=T))
object@fulliterations <- lapply(object@fulliterations, function(l){
row.names(l)<-labels[, 2]
l
})
object@iterations <- do.call(cbind, lapply(object@fulliterations, function(l)l$OoverE))
object@oeresults <- data.frame(labels, apply(object@iterations, 1, mean))
names(object@oeresults) <- c("StationCode", "SampleID", "OoverE")
object
})
oe <- new("oe", bugs, stations)
oescore <- score(oe)
traceback()
setMethod("rForest", "oe", function(object){
if(nrow(object@oesubsample)==0){object <- subsample(object)}
load("oe_stuff.rdata")
object@predictors <- merge(unique(object@oesubsample[, c("StationCode", "SampleID")]), object@predictors,
by="StationCode")
row.names(object@predictors) <- paste0(object@predictors$StationCode, "%", object@predictors$SampleID)
print(length(unique(object@predictors$SampleID)))
iterate <- function(rep){
patable <- dcast(data=object@oesubsample[, c("StationCode", "SampleID", "STE", rep)],
StationCode + SampleID ~ STE,
value.var=rep,
fun.aggregate=function(x)sum(x)/length(x))
patable[is.na(patable)] <- 0
row.names(patable) <- paste(patable$StationCode, "%", patable$SampleID, sep="")
iresult <- model.predict.RanFor.4.2(bugcal.pa=oe_stuff[[2]],
grps.final=oe_stuff[[3]],
preds.final=oe_stuff[[4]]),
ranfor.mod=oe_stuff[[1]],
prednew=object@predictors,
bugnew=patable,
Pc=0.5,
Cal.OOB=FALSE)
iresult$SampleID <- unique(patable$SampleID)
return(iresult)
}
object@fulliterations <- lapply(paste("Replicate", 1:20), function(i)iterate(i))
labels <- strsplit(row.names(object@fulliterations[[1]]), "%")
labels <- as.data.frame(matrix(unlist(labels), nrow=length(labels), byrow=T))
object@fulliterations <- lapply(object@fulliterations, function(l){
row.names(l)<-labels[, 2]
l
})
object@iterations <- do.call(cbind, lapply(object@fulliterations, function(l)l$OoverE))
object@oeresults <- data.frame(labels, apply(object@iterations, 1, mean))
names(object@oeresults) <- c("StationCode", "SampleID", "OoverE")
object
})
setMethod("rForest", "oe", function(object){
if(nrow(object@oesubsample)==0){object <- subsample(object)}
load("oe_stuff.rdata")
object@predictors <- merge(unique(object@oesubsample[, c("StationCode", "SampleID")]), object@predictors,
by="StationCode")
row.names(object@predictors) <- paste0(object@predictors$StationCode, "%", object@predictors$SampleID)
print(length(unique(object@predictors$SampleID)))
iterate <- function(rep){
patable <- dcast(data=object@oesubsample[, c("StationCode", "SampleID", "STE", rep)],
StationCode + SampleID ~ STE,
value.var=rep,
fun.aggregate=function(x)sum(x)/length(x))
patable[is.na(patable)] <- 0
row.names(patable) <- paste(patable$StationCode, "%", patable$SampleID, sep="")
iresult <- model.predict.RanFor.4.2(bugcal.pa=oe_stuff[[2]],
grps.final=oe_stuff[[3]],
preds.final=oe_stuff[[4]],
ranfor.mod=oe_stuff[[1]],
prednew=object@predictors,
bugnew=patable,
Pc=0.5,
Cal.OOB=FALSE)
iresult$SampleID <- unique(patable$SampleID)
return(iresult)
}
object@fulliterations <- lapply(paste("Replicate", 1:20), function(i)iterate(i))
labels <- strsplit(row.names(object@fulliterations[[1]]), "%")
labels <- as.data.frame(matrix(unlist(labels), nrow=length(labels), byrow=T))
object@fulliterations <- lapply(object@fulliterations, function(l){
row.names(l)<-labels[, 2]
l
})
object@iterations <- do.call(cbind, lapply(object@fulliterations, function(l)l$OoverE))
object@oeresults <- data.frame(labels, apply(object@iterations, 1, mean))
names(object@oeresults) <- c("StationCode", "SampleID", "OoverE")
object
})
oescore <- score(oe)
library(reshape2)
oescore <- score(oe)
###OE model prediction###
model.predict.RanFor.4.2 <-function(bugcal.pa,grps.final,preds.final,ranfor.mod, prednew,bugnew,Pc,Cal.OOB=FALSE) {;
#first convert bug matrix to P/A (1/0);
temp.pa <- bugnew[, 3:ncol(bugnew)];
temp.pa[temp.pa>0]<-1;
rm(bugnew);
#1. - initial definitions;
names(grps.final)<-row.names(bugcal.pa);
nsite.cal<-length(grps.final); #number of calibration sites;
npreds<-length(preds.final); #number of predictor variables;
grpsiz<-table(grps.final); #tabulate sites per group;
ngrps<-length(grpsiz);  #number of groups;
#2. Alignment of new predictor and bug data with model data;
#2a) Align the rows (samples) of the new bug data to the new predictor data;
temp.pa<-temp.pa[row.names(prednew),];
#2b)reshape bugnew columns (taxa) to match those in bugcal.pa, and be in same order;
# New bug data might have fewer or more columns (taxa) than calibration bug data;
# create a new empty site x taxa matrix with bugcal.pa columns and bugnew rows, fill it with zeros;
nsite.new<-dim(temp.pa)[[1]];
ntaxa<-dim(bugcal.pa)[[2]];
bugnew.pa<-matrix(rep(0,nsite.new*ntaxa),nrow=nsite.new,dimnames=list(rownames(temp.pa),names(bugcal.pa)));
#loop through columns of new matrix and fill with columns of the original test data matrix;
col.match<-match(dimnames(bugnew.pa)[[2]],dimnames(temp.pa)[[2]]);
for(kcol in 1:ntaxa) if(!is.na(col.match[kcol]))bugnew.pa[,kcol]<-temp.pa[,col.match[kcol]];
################;
## STEP 3. -- Use RF to predict the group (cluster) membership for all new sites. ;
# Does not use RIVPACS assumption of weighting the membership probabilities by Calibration group size, as a prior probability;
# Also, RF predictions do not have an outlier test, unlike DFA predictions;
# Predicted probs are outputted as a matrix, sites are rows, columns are groups;
#If Cal.OOB is true, do OOB predictions, appropriate ONLY for CAL data;
# If it is false, do a new prediction;
if(Cal.OOB==TRUE) grpprobs<-ranfor.mod$votes else
grpprobs<-predict(ranfor.mod,newdata=prednew[,preds.final],type='prob');
############;
#STEP 4 -- Compute predicted occurrence probability for each modeled taxon at each new sample;
# "modeled OTU's" consist of all taxa that were found at >=1 calibration sample;
#To do this, first calculate the occurrence freqs of all modeled taxa in the Calibration sample groups;
grpocc<-apply(bugcal.pa,2,function(x){tapply(x,grps.final,function(y){sum(y)/length(y)})});
#finally, compute the matrix of predicted occurrence (capture) probabilities, for all new samples and all modeled taxa;
#This is the matrix-algebra form of the RIVPACS combining formula (e.g., Clarke et al. 2003, Eq. 4)
site.pred.dfa<-grpprobs%*%grpocc;
#######################;
# STEP 5. Compute O, E, O/E and BC for all samples. ;
# Also compute O/E and BC for the null model;
#5.1 loop over all samples. Compute and store  O, predicted E, predicted BC for each sample. ;
#temporary data frame to hold nonnull results for all samples. ;
nsit.new<-dim(prednew)[[1]];
OE.stats<-data.frame(OBS=rep(NA,nsit.new), E.prd=rep(NA,nsit.new),BC.prd=rep(NA,nsit.new),row.names=row.names(prednew));
for(i in 1:nsit.new) {;
#i<-1;
cur.prd<-site.pred.dfa[i,]; #vector of predicted probs for current sample;
spdyn<-names(cur.prd)[cur.prd>=Pc];  #subset of taxa with Pi>=Pcutoff;
cur.prd<-cur.prd[spdyn]; #vector of Pi for subset of included taxa;
cur.obs<-bugnew.pa[i,spdyn]; #vector of observed P/A for those taxa;
OE.stats$OBS[i]<-sum(cur.obs); #observed richness (O);
OE.stats$E.prd[i]<-sum(cur.prd); #Expected richness (E);
OE.stats$BC.prd[i]<-sum(abs(cur.obs-cur.prd))/ (OE.stats$OBS[i]+OE.stats$E.prd[i]); #BC value;
}; #finish sample loop;
#5.2 - Compute Expected richness (E) and BC for null model using taxa >= Pc.
# Note that the set of taxa included in the null model is fixed for all samples;
pnull<-apply(bugcal.pa,2,sum)/dim(bugcal.pa)[[1]];  #null model predicted occurrnece probabilities, all taxa;
nulltax<-names(pnull[pnull>=Pc]); #subset of taxa with Pnull >= Pc;
Enull<-sum(pnull[nulltax]);
Obsnull<-apply(bugnew.pa[,nulltax],1,sum); #vector of Observed richness, new samples, under null model;
BC.null<-apply(bugnew.pa[,nulltax],1,function(x)sum(abs(x-pnull[nulltax])))/(Obsnull+Enull); #vector of null-model BC;
#5.3 - Final data frame contains values of O, E, O/E, Onull, Enull, Onull/Enull, BC.prd and BC.null, for all samples;
#Also includes outlier flags;
OE.final<-data.frame(O=OE.stats$OBS,E=OE.stats$E.prd,
OoverE=OE.stats$OBS/OE.stats$E.prd,
Onull=Obsnull,Enull=rep(Enull,length(Obsnull)),OoverE.null=Obsnull/Enull,
BC= OE.stats$BC.prd,BC.null=BC.null,
row.names=row.names(bugnew.pa));
return(OE.final)
}; #end of function;
oescore <- score(oe)
length(unique(stations$StationCode))
setMethod("rForest", "oe", function(object){
if(nrow(object@oesubsample)==0){object <- subsample(object)}
load("oe_stuff.rdata")
object@predictors <- merge(unique(object@oesubsample[, c("StationCode", "SampleID")]), object@predictors,
by="StationCode", all.x=FALSE)
row.names(object@predictors) <- paste0(object@predictors$StationCode, "%", object@predictors$SampleID)
print(length(unique(object@predictors$SampleID)))
iterate <- function(rep){
patable <- dcast(data=object@oesubsample[, c("StationCode", "SampleID", "STE", rep)],
StationCode + SampleID ~ STE,
value.var=rep,
fun.aggregate=function(x)sum(x)/length(x))
patable[is.na(patable)] <- 0
row.names(patable) <- paste(patable$StationCode, "%", patable$SampleID, sep="")
iresult <- model.predict.RanFor.4.2(bugcal.pa=oe_stuff[[2]],
grps.final=oe_stuff[[3]],
preds.final=oe_stuff[[4]],
ranfor.mod=oe_stuff[[1]],
prednew=object@predictors,
bugnew=patable,
Pc=0.5,
Cal.OOB=FALSE)
iresult$SampleID <- unique(patable$SampleID)
return(iresult)
}
object@fulliterations <- lapply(paste("Replicate", 1:20), function(i)iterate(i))
labels <- strsplit(row.names(object@fulliterations[[1]]), "%")
labels <- as.data.frame(matrix(unlist(labels), nrow=length(labels), byrow=T))
object@fulliterations <- lapply(object@fulliterations, function(l){
row.names(l)<-labels[, 2]
l
})
object@iterations <- do.call(cbind, lapply(object@fulliterations, function(l)l$OoverE))
object@oeresults <- data.frame(labels, apply(object@iterations, 1, mean))
names(object@oeresults) <- c("StationCode", "SampleID", "OoverE")
object
})
oescore <- score(oe)
setMethod("rForest", "oe", function(object){
if(nrow(object@oesubsample)==0){object <- subsample(object)}
load("oe_stuff.rdata")
object@predictors <- merge(unique(object@oesubsample[, c("StationCode", "SampleID")]), object@predictors,
by="StationCode", all.x=FALSE)
row.names(object@predictors) <- paste0(object@predictors$StationCode, "%", object@predictors$SampleID)
iterate <- function(rep){
patable <- dcast(data=object@oesubsample[, c("StationCode", "SampleID", "STE", rep)],
StationCode + SampleID ~ STE,
value.var=rep,
fun.aggregate=function(x)sum(x)/length(x))
patable[is.na(patable)] <- 0
row.names(patable) <- paste(patable$StationCode, "%", patable$SampleID, sep="")
iresult <- model.predict.RanFor.4.2(bugcal.pa=oe_stuff[[2]],
grps.final=oe_stuff[[3]],
preds.final=oe_stuff[[4]],
ranfor.mod=oe_stuff[[1]],
prednew=object@predictors,
bugnew=patable,
Pc=0.5,
Cal.OOB=FALSE)
iresult$SampleID <- unique(object@predictors$SampleID)
return(iresult)
}
object@fulliterations <- lapply(paste("Replicate", 1:20), function(i)iterate(i))
labels <- strsplit(row.names(object@fulliterations[[1]]), "%")
labels <- as.data.frame(matrix(unlist(labels), nrow=length(labels), byrow=T))
object@fulliterations <- lapply(object@fulliterations, function(l){
row.names(l)<-labels[, 2]
l
})
object@iterations <- do.call(cbind, lapply(object@fulliterations, function(l)l$OoverE))
object@oeresults <- data.frame(labels, apply(object@iterations, 1, mean))
names(object@oeresults) <- c("StationCode", "SampleID", "OoverE")
object
})
oescore <- score(oe)
summary(oescore)
oeoutput <- summary(oescore)
viewData(merge(oeoutput[, c("SampleID", "OoverE")], validation[, c("SampleID", "OoverE")], by="SampleID"))
viewData(merge(oeoutput[, c("SampleID", "OoverE")], validation[, c("SampleID", "OoverE")], by="SampleID"), all.y=TRUE)
viewData(merge(oeoutput[, c("SampleID", "OoverE")], validation[, c("SampleID", "OoverE")], by="SampleID", all.y=TRUE))
viewData(merge(oeoutput[, c("SampleID", "OoverE")], validation[, c("SampleID", "OoverE")], by="SampleID"))
viewData(merge(output[, c("SampleID", "MMI_Score", "Shannon_Diversity")], validation[, c("SampleID", "MMI", "Shannon_Diversity")], by="SampleID"))
viewData(merge(oeoutput[, c("SampleID", "OoverE")], validation[, c("SampleID", "OoverE")], by="SampleID"))
viewData(oeoutput)
scores <- score(nameMatch(mmi, 1))
output <- summary(scores)
source('~/.active-rstudio-document', echo=TRUE)
scores <- score(nameMatch(mmi, 1))
traceback()
scores <- score(nameMatch(mmi, 2))
traceback()
setMethod("subsample", "mmi", function(object){
if(is.null(object@bugdata$distinct)){object <- nameMatch(object)}
object@datalength <- length(object@bugdata)
object@bugdata$SampleID <- as.character(object@bugdata$SampleID)
rarifydown <- function(data){unlist(sapply(unique(data$SampleID), function(sample){
v <- data[data$SampleID==sample, "Result"]
if(sum(v)>=500){rrarefy(v, 500)} else
{v}
}))}
registerDoParallel()
rarificationresult <- foreach(i=1:20, .combine=cbind, .packages="vegan") %dopar% {
rarifydown(object@bugdata)
}
closeAllConnections()
object@subsample <- as.data.frame(cbind(object@bugdata, rarificationresult))
colnames(object@subsample)[(object@datalength + 1):(object@datalength + 20)]<- paste("Replicate", 1:20)
return(object)
})
scores <- score(nameMatch(mmi, 2))
output <- summary(scores)
names(output)[6] <- "Tolerance_Value"
viewData(merge(output[, c("SampleID", "MMI_Score", "Shannon_Diversity")], validation[, c("SampleID", "MMI", "Shannon_Diversity")], by="SampleID"))
scores <- score(nameMatch(mmi, 1))
output <- summary(scores)
viewData(merge(output[, c("SampleID", "MMI_Score", "Shannon_Diversity")], validation[, c("SampleID", "MMI", "Shannon_Diversity")], by="SampleID"))
viewData(output)
viewData(merge(output[, c("SampleID", "MMI_Score", "Shannon_Diversity")], validation[, c("SampleID", "MMI", "Shannon_Diversity")], by="SampleID"))
output <- summary(scores)
viewData(output)
validation_merge <- merge(output[, c("SampleID", "MMI_Score", names)], validation[, c("SampleID", "MMI", names)], by="SampleID")
validation_merge <- merge(output[, c("SampleID", "MMI Score", names)], validation[, c("SampleID", "MMI", names)], by="SampleID")
names(output)[6] <- "Tolerance_Value"
validation_merge <- merge(output[, c("SampleID", "MMI_Score", names)], validation[, c("SampleID", "MMI", names)], by="SampleID")
viewData(validation_merge)
scores <- score(nameMatch(mmi, 1))
source('~/.active-rstudio-document', echo=TRUE)
scores <- score(nameMatch(mmi, 1))
output <- summary(scores)
viewData(merge(output[, c("SampleID", "MMI_Score", "Shannon_Diversity")], validation[, c("SampleID", "MMI", "Shannon_Diversity")], by="SampleID"))
source('P:/PartTimers/MarkEngeln/bug_mmi/redo.r', echo=TRUE)
abs(validation_merge$MMI_Score - validation_merge$MMI)
oescore@oeresults
summary(oescore, "full")
summary(oescore, "detail")
summary(oescore, "detailed")
summary(new("metricMean", scores, oescore))
new("metricMean", scores, oescore)
source('~/.active-rstudio-document', echo=TRUE)
summary(new("metricMean", scores, oescore))
oescore@fulliterations[[1]]
oescore@fulliterations[[1]][, c("SampleID", "E")]
oescore@fulliterations[[1]][, c("SampleID", "0", "E")]
names(oescore@fulliterations[[1]])
oescore@fulliterations[[1]][, c("O", "E")]
oescore@fulliterations[[1]][, c("SampleID", "O", "E")]
oescore@fulliterations[[2]][, c("SampleID", "O", "E")]
merge(oescore@fulliterations[[2]][, c("SampleID","OoverE", "O", "E")], validation[, c("SampleID", "OoverE", "O", "E")], by="SampleID")
viewData(merge(oescore@fulliterations[[2]][, c("SampleID","OoverE", "O", "E")], validation[, c("SampleID", "OoverE", "O", "E")], by="SampleID"))
viewData(merge(output[, c("SampleID", "MMI_Score", "Shannon_Diversity")], validation[, c("SampleID", "MMI", "Shannon_Diversity")], by="SampleID"))
oescore@fulliterations[[1]]
viewData(oescore@fulliterations[[1]])
bugsnew <- subset(bugs, SampleID %in% intersect(bugs$StationCode, stations$StationCode))
intersect(bugs$StationCode, stations$StationCode)
bugsnew <- subset(bugs, SampleID %in% intersect(StationCode, stations$StationCode))
bugsnew <- bugs[bugs$SampleID %in% intersect(bugs$StationCode, stations$StationCode)])
bugsnew <- bugs[bugs$SampleID %in% intersect(bugs$StationCode, stations$StationCode)]
bugsnew <- bugs[bugs$SampleID %in% intersect(bugs$StationCode, stations$StationCode),]
intersect(bugs$StationCode, stations$StationCode)
bugs$SampleID %in% intersect(bugs$StationCode, stations$StationCode)
bugsnew <- bugs[bugs$StationCode %in% intersect(bugs$StationCode, stations$StationCode),]
fulltest <- new("metricMean", new("mmi", bugsnew, stations), new("oe", bugsnew, stations))
mmi_result <- new("mmi", bugsnew, stations)
oe_result <- new("oe", bugsnew, stations)
fulltest <- new("metricMean", mmi_result, oe_result)
summary(mmi_result)
mmi_result <- score(new("mmi", bugsnew, stations))
oe_result <- score(new("oe", bugsnew, stations))
fulltest <- new("metricMean", mmi_result, oe_result)
viewData(summary(fulltest))
fulltest <- new("metricMean", mmi_result, oe_result, "complete")
str(summary(fulltest, "complete"))
str(summary(fulltest, "detailed"))
str(summary(fulltest))
str(summary(fulltest, "standard"))
names(fulltest@metrics)
names(fulltest@modelprediction)
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class3_metricMean.r', echo=TRUE)
str(summary(fulltest))
str(summary(fulltest, "detailed"))
source('~/.active-rstudio-document', echo=TRUE)
str(summary(fulltest, "detailed"))
source('~/.active-rstudio-document', echo=TRUE)
str(summary(fulltest, "detailed"))
source('~/.active-rstudio-document', echo=TRUE)
str(summary(fulltest, "detailed"))
fulltest@oeresults
fulltest@iterations
apply(bugcal.pa,2,function(x){tapply(x,grps.final,function(y){sum(y)/length(y)})})
predict(oe_stuff[[1]],newdata=fulltest@predictors[,oe_stuff[[4]]],type='prob') %*% apply(bugcal.pa,2,function(x){tapply(x,grps.final,function(y){sum(y)/length(y)})})
source('~/.active-rstudio-document', echo=TRUE)
str(summary(fulltest, "detailed"))
viewData(summary(fulltest, "detailed"))
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class3_metricMean.r', echo=TRUE)
fulltest <- new("metricMean", mmi_result, oe_result)
viewData(summary(fulltest, "detailed"))
viewData(summary(fulltest, "detailed"))
viewData(summary(fulltest, "detailed"))
viewData(fulltest@metrics)
source('~/.active-rstudio-document', echo=TRUE)
mmi_result <- score(new("mmi", bugsnew, stations))
oe_result <- score(new("oe", bugsnew, stations))
fulltest <- new("metricMean", mmi_result, oe_result)
viewData(summary(fulltest, "detailed"))
viewData(merge(summary(fulltest), validation[, c("SampleID", "MMI", "OoverE", "CSCI")], by="SampleID"))
viewData(summary(fulltest, "detailed"))
str(summary(fullest, "complete"))
str(summary(fulltest, "complete"))
names(summary(fulltest, "complete"))
str(summary(fulltest, "complete"))
source('P:/PartTimers/MarkEngeln/bug_mmi/hybridindex/R/class3_metricMean.r', echo=TRUE)
str(summary(fulltest, "complete"))
viewData(summary(fulltest, "detailed"))
